# Karpathy Zero to Hero â€” Practice

This repository tracks my **hands-on implementations and projects**
from **Andrej Karpathyâ€™s â€œNeural Networks from Scratch / Zero to Heroâ€ series**.

Each sub-project lives in its **own dedicated repository** and contains:
- clean implementation code
- small experiments and sanity checks
- notes and insights from the videos

This repo serves as a **learning index and roadmap**, not a code dump.

---

## ğŸš€ Projects

| Project   | Status       | Repo |
|----------|-------------|------|
| micrograd | âœ… Completed | https://github.com/banatehrani/micrograd-notes |
| makemore  | â³ Planned   | â€” |
| nanoGPT   | â³ Planned   | â€” |

---

## ğŸ§  What â€œCompletedâ€ means (micrograd)

For **micrograd**, completion means:
- Reverse-mode autodiff engine built from scratch
- MLP (Neuron / Layer / MLP) implemented on top
- Training loop on a toy dataset
- Gradient flow verified via backprop
- Graph visualization using Graphviz
- Code written incrementally while learning (not copy-pasted)

The original micrograd repo is forked **only for reference and traceability**.

---

## ğŸ¯ Goal

My goal is to:
- Understand every concept deeply
- Implement everything from first principles
- Use modern Python and clean project structure
- Document learning clearly and honestly
- Showcase results in a professional way

---

## ğŸ”— Useful Links

- Original playlist:  
  https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
- Andrej Karpathyâ€™s GitHub:  
  https://github.com/karpathy